.. _setup:

Setting up
***********

Installation
=============

Clone the LHAT repository locally from https://github.com/openearth/lhat

.. code-block:: text

      >> git clone https://github.com/openearth/lhat.git

Navigate to the directory where you cloned the repository and create a conda environment from the yml file.

.. code-block:: text

      >> conda env create -f environment.yml

Once the environment is created, activate it and import lhat. Ensure your working
directory is the same root folder of the cloned repository.

Activate the conda environment
.. code-block:: text

      >> conda activate lhat

Import LHAT as so
.. code-block:: python

      >>> import lhat

Run the example script in your command line
.. code-block:: text

      >> python example.py


Parameterising LHAT
===================

The LHAT tool requires some parameters. The following arguments are necessary:
* Name of project
* Coordinate Referencing System (crs)
* Path to where your landslide point dataset is (accepts JSON or .shp format)
* A random state (necessary for reproducability of data)
* Bounding box for clipping public assets
* inputs (dictionary)
* no_data values (can be a list or single value)
* Pixel resolution (important for the retrieval of online datasets)
* Kernel size (default 3x3): necessary for defining an area as 'landslide', since
a landslide does not occur as locally as a point but as an area affected.

.. note::
        Not all input data have an online source. For those that do not, using
        the 'online' option will return nothing.

The following code snippet can be used for the initial parameterisation, also
available in example.py that is placed in the root of the lhat repository.

.. literalinclude:: ../../example.py
        :language: python
        :caption: Example of parameterising inputs
        :lines: 11-77


Data engineering step
======================
